# medical_paper_filter_batch_processor_FIXED_V5.py
import json
import os
import re
import math
from typing import Dict, Any, List

import pandas as pd
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
import itertools


# ===========================
# ğŸ§  æç¤ºè¯ï¼ˆPromptï¼‰é…ç½®åŒºï¼ˆè¯·åœ¨æ­¤å¤„ä¿®æ”¹åˆ¤æ–­é€»è¾‘ï¼‰
# ===========================

JSON_OUTPUT_TEMPLATE = {
    "Title": "è®ºæ–‡åŸæ ‡é¢˜å ä½ç¬¦",
    "Title Translation": "æ ‡é¢˜çš„ä¸­æ–‡ç¿»è¯‘",
    "MedicalDiagnosisPrognosisRelevance": "é«˜/ä¸­/ä½",
    "Reason1": "ç®€çŸ­ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼šè§£é‡Šä¸åŒ»å­¦è¯Šæ–­/é¢„åç›¸å…³çš„ç¨‹åº¦ã€‚",
    "FewZeroShotRelevance": "é«˜/ä¸­/ä½",
    "Reason2": "ç®€çŸ­ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼šè§£é‡Šä¸å°‘æ ·æœ¬/é›¶æ ·æœ¬ç›¸å…³çš„ç¨‹åº¦ã€‚",
    "BodyPart": "è‚ºéƒ¨/è„‘/ä¹³è…º/çœ¼åº•/çš®è‚¤/å¿ƒè„/é€šç”¨/å…¶ä»–",
    "Reason3": "ç®€çŸ­ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼šè§£é‡Šæ¶‰åŠçš„èº«ä½“éƒ¨ä½ã€‚",
    "Recommendation": "å¼ºçƒˆæ¨è/ä¸€èˆ¬æ¨è/ä¸æ¨è"
}

SYSTEM_PROMPT = f'''ä½ æ˜¯ä¸€ååŒ»å­¦äººå·¥æ™ºèƒ½æ–¹å‘çš„ç§‘ç ”åŠ©ç†ï¼Œå½“å‰ä»»åŠ¡æ˜¯æ ¹æ®è®ºæ–‡æ ‡é¢˜å¯¹å…¶è¿›è¡Œè¯¦ç»†åˆ†æã€‚
è¯·ä¸¥æ ¼åˆ†æä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒæ–¹é¢ï¼š
1. **åŒ»å­¦è¯Šæ–­/é¢„åç›¸å…³æ€§**ï¼šæ˜¯å¦ä¸åŒ»ç–—/åŒ»å­¦å›¾åƒã€è¯Šæ–­ (Diagnosis)ã€é¢„å (Prognosis) ç›¸å…³ã€‚
2. **å°‘/é›¶æ ·æœ¬ç›¸å…³æ€§**ï¼šæ˜¯å¦ä¸å°‘æ ·æœ¬ (Few-shot)ã€é›¶æ ·æœ¬ (Zero-shot) æˆ–è¿ç§»å­¦ä¹ ç›¸å…³ã€‚
3. **æ¶‰åŠçš„èº«ä½“éƒ¨ä½**ï¼šæ˜ç¡®æåŠæˆ–å¼ºçƒˆæš—ç¤ºçš„æ“ä½œå¯¹è±¡ã€‚

è¯·ä¸¥æ ¼ä»…è¾“å‡º JSON æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–è¯´æ˜æˆ– Markdown æ ¼å¼ã€‚
ä½ å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹ **JSON** æ ¼å¼è¾“å‡ºï¼ŒTitle å­—æ®µå¿…é¡»æ˜¯è¾“å…¥çš„åŸæ ‡é¢˜ï¼š
{json.dumps(JSON_OUTPUT_TEMPLATE, ensure_ascii=False, indent=2)}
'''


# ===========================
# æ ¸å¿ƒå‡½æ•°ï¼šDeepSeek è®ºæ–‡æ ‡é¢˜åˆ¤æ–­ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
# ===========================

def deepseek_judge_paper_json(title: str, api_key: str) -> Dict[str, Any]:
    user_prompt = f"è®ºæ–‡æ ‡é¢˜ï¼š{title}"
    
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ],
            response_format={'type': 'json_object'},
            stream=False,
            temperature=0.0
        )
        raw_output = response.choices[0].message.content.strip()
        result = json.loads(raw_output)
        result['Original_Title'] = title
        return result

    except Exception as e:
        error_msg = f"API æˆ–è§£æå¤±è´¥: {str(e)[:50]}"
        print(f"âŒ é”™è¯¯: {error_msg} (æ ‡é¢˜: {title[:30]}...)")
        return {
            "Original_Title": title,
            "Title": title,
            "Title Translation": "N/A",
            "MedicalDiagnosisPrognosisRelevance": "ä½",
            "Reason1": error_msg,
            "FewZeroShotRelevance": "ä½",
            "Reason2": "N/A",
            "BodyPart": "N/A",
            "Reason3": "N/A",
            "Recommendation": "ä¸æ¨è"
        }


# ===========================
# æ‰¹é‡å¤„ç† Excelï¼šè‡ªåŠ¨è¾“å‡ºè·¯å¾„ + æ–­ç‚¹ç»­ä¼  + å¹¶å‘
# ===========================

def batch_process_excel(input_path: str, api_keys: List[str]):
    # è‡ªåŠ¨æ„é€ è¾“å‡ºè·¯å¾„ï¼šåŒç›®å½•ï¼Œæ–‡ä»¶ååŠ  _ds åç¼€
    input_dir = os.path.dirname(input_path)
    input_basename = os.path.basename(input_path)
    name, ext = os.path.splitext(input_basename)
    output_path = os.path.join(input_dir, f"{name}_ds{ext}")

    ORIGINAL_COLS = ["Part", "Title", "Pages"]
    RESULT_COL_MAP = {
        "Title Translation": "Title Translation",
        "MedicalDiagnosisPrognosisRelevance": "MedicalDiagnosisPrognosisRelevance",
        "Reason1": "Reason1",
        "FewZeroShotRelevance": "FewZeroShotRelevance",
        "Reason2": "Reason2",
        "BodyPart": "BodyPart",
        "Reason3": "Reason3",
        "Recommendation": "Recommendation"
    }
    RESULT_COLS = list(RESULT_COL_MAP.values())

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼ˆè™½ç„¶ä¸è¾“å…¥åŒç›®å½•ï¼Œä½†ä¿æŒå¥å£®æ€§ï¼‰
    os.makedirs(input_dir, exist_ok=True)

    # 1. è¯»å–åŸå§‹æ•°æ®
    df_original = pd.read_excel(input_path)
    if "Title" not in df_original.columns:
        raise ValueError("è¾“å…¥ Excel æ–‡ä»¶ç¼ºå°‘ 'Title' åˆ—")

    # 2. å°è¯•åŠ è½½å·²æœ‰ç»“æœï¼ˆç”¨äºç»­ä¼ ï¼‰
    df_results = None
    if os.path.exists(output_path):
        print(f"âœ… æ£€æµ‹åˆ°å·²æœ‰è¾“å‡ºæ–‡ä»¶ï¼Œå°è¯•è¯»å–å·²å¤„ç†ç»“æœï¼š{output_path}")
        df_results = pd.read_excel(output_path)
        if "Title" not in df_results.columns:
            print("âš ï¸ è­¦å‘Š: è¾“å‡ºæ–‡ä»¶ç¼ºå°‘ 'Title' åˆ—ï¼Œå°†å¿½ç•¥å·²å­˜åœ¨çš„ç»“æœã€‚")
            df_results = None

    # 3. åˆå§‹åŒ–æœ€ç»ˆ DataFrame
    df_final = df_original.copy()
    for col in RESULT_COLS:
        if col not in df_final.columns:
            df_final[col] = None

    # 4. åŒæ­¥å·²æœ‰ç»“æœ
    synced_count = 0
    if df_results is not None:
        processed_data = df_results.set_index('Title')[RESULT_COLS]
        for idx, row in df_final.iterrows():
            title = str(row.get("Title", "")).strip()
            if not title or title.lower() in ("nan", "none"):
                continue
            if title in processed_data.index:
                rec = processed_data.loc[title, 'Recommendation']
                is_filled = (
                    isinstance(rec, str)
                    and rec.strip().lower() not in ["", "none", "nan", "n/a"]
                    and pd.notna(rec)
                )
                if is_filled:
                    for col in RESULT_COLS:
                        df_final.loc[idx, col] = processed_data.loc[title, col]
                    synced_count += 1
        print(f"   å·²åŒæ­¥ {synced_count} æ¡å·²å¤„ç†ç»“æœåˆ°å½“å‰æ‰¹æ¬¡ã€‚")

    # 5. æ”¶é›†å¾…å¤„ç†ä»»åŠ¡
    tasks_to_run = []
    total_rows = len(df_final)
    for idx, row in df_final.iterrows():
        title = str(row.get("Title", "")).strip()
        if not title or title.lower() in ("nan", "none"):
            continue

        recommendation_value = row.get("Recommendation")
        is_processed = False
        if isinstance(recommendation_value, str) and recommendation_value.strip().lower() not in ["", "none", "nan", "n/a"]:
            is_processed = True
        elif pd.notna(recommendation_value):
            is_processed = False

        if is_processed:
            print(f"â© è·³è¿‡å·²å¤„ç† [{idx+1}/{total_rows}]: {title[:50]}...")
            continue

        tasks_to_run.append({'index': idx, 'title': title})

    rows_to_process = len(tasks_to_run)
    print(f"\n--- å¾…å¤„ç†æ€»è¡Œæ•°: {total_rows} | æ–°ä»»åŠ¡æ•°: {rows_to_process} ---")

    if rows_to_process == 0:
        print("ğŸ‰ æ‰€æœ‰æ•°æ®å‡å·²å¤„ç†å®Œæˆï¼Œæ— éœ€è¿è¡Œæ–°ä»»åŠ¡ã€‚")
        return

    # 6. å¹¶å‘å¤„ç†
    api_key_cycler = itertools.cycle(api_keys)
    max_workers = min(len(api_keys), 10)  # é˜²æ­¢çº¿ç¨‹è¿‡å¤šï¼ˆå¯è°ƒï¼‰
    results_list = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {}
        for task in tasks_to_run:
            idx = task['index']
            title = task['title']
            key = next(api_key_cycler)
            future = executor.submit(deepseek_judge_paper_json, title, key)
            futures[future] = idx

        for future in as_completed(futures):
            idx = futures[future]
            try:
                result = future.result()
                results_list.append((idx, result))
                print(f"âœ” å®Œæˆ [{idx+1}/{total_rows}] | ç»“æœ: {result.get('Recommendation', 'N/A')} | æ ‡é¢˜: {result.get('Title', 'N/A')[:80]}...")
            except Exception as e:
                print(f"âŒ çº¿ç¨‹æ‰§è¡Œé”™è¯¯ (Index: {idx}): {e}")

    # 7. æ›´æ–°å¹¶ä¿å­˜
    for idx, result in results_list:
        for json_key, excel_col in RESULT_COL_MAP.items():
            df_final.at[idx, excel_col] = result.get(json_key, "N/A")

    df_final.to_excel(output_path, index=False)

    print(f"\n{'='*60}")
    print(f"ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼å…±å¤„ç† {rows_to_process} è¡Œæ–°æ•°æ®ã€‚")
    print(f"ğŸ“ æœ€ç»ˆè¾“å‡ºæ–‡ä»¶ï¼š{output_path}")
    print(f"{'='*60}")


# ======================
# ä¸»ç¨‹åºå…¥å£
# ======================
if __name__ == "__main__":
    API_KEYS = [
        "sk-8c38624bafb9477fb237ab2e58948c1b",
        "sk-4d5cc37a8b17417c87ed33b94d7b06a7",
        "sk-ab036985ba2c452f8262f4922e8ab50c",
        "sk-989bea94ce2b47e59714145005afc87e",
        "sk-29bc65dfb2de4ed3a983741f815ad2d7",
        "sk-064831a959c84353b6c4979fa90d16f3",
        "sk-82923973f2ff4ef895824595474f0df6",
        "sk-f0556cdf91f74729b7615d46fad4091c",
        "sk-6019eb2fda48482aa2218d3283f8332d",
        "sk-c19ad12b9f4b4b078270651858bb7f68",
    ]

    INPUT_EXCEL = r"E:OneDrive - CUHK-ShenzhenOutside School2511MED_Interncodefind_paperoutputgoogle_scholar_output.xlsx"

    batch_process_excel(INPUT_EXCEL, API_KEYS)